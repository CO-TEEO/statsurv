#' @title Extract fitted values from a model fit object
#'
#' @description A consistent method for extracting fitted values from a model fit object.
#'   `extract_yhat` returns point estimates for the fitted values while `sample_yhat` returns 1 or
#'   more random samples from the fitted values, using the variance-covariance matrix of the
#'   coefficients.
#'
#' @param space_coord A gridcoord object (\code{\link[gridcoord]{gc_gridcoord}}) describing the
#'   spatial area that is covered by `fit` and `data`.
#' @param time_coord A gridcoord object (\code{\link[gridcoord]{gc_gridcoord}}) describing the time
#'   span that is covered by `fit` and `data`, as well as any additional time points for which
#'   outcome variables should be predicted.  This coordinate must be ordered, with the first entries
#'   in the dataframe corresponding to the earliest time periods and the last entries corresponding
#'   to the most recent.
#' @param fit A model fit object, such as that generated by `lm` or `glm`.
#' @param data A data.frame containig the data that should be used to predict the fitted values.
#'   Must have all of the covariates used by the model fit object to calculate fitted values, as
#'   well as columns corresponding to `space_coord` and `time_coord`
#' @param ... Additional arguments passed into other methods
#'
#' @details For `lm`  and `glm` models, `extract_yhat` is a friendly wrapper around the
#'   \code{\link[stats]{predict}} method, but it can also extract fitted values from some models
#'   that do not have `predict` methods, including `INLA` and `forecast_ARIMA` models. `sample_yhat`
#'   uses the \code{\link[arm]{sim}} function to draw samples of the fitted values for `lm` and
#'   `glm` models.

#' @return A data.frame whose first two columns correspond to `space_coord` and `time_coord`, and
#'   whose remaining columns are the point estimates or random samples of the fitted values.
#' @describeIn extract_yhat Return point estimates for fitted values
#' @export
#' @seealso \code{\link{extract_yhat.forecast_ARIMA}}
#' @md
#' @examples
#' library("scanstatistics")
#' nm_county_coord <- statsurv::nm_county_coord
#' data(NM_popcas)
#' year_coord <- generate_date_range(lubridate::ymd("1973-01-01"),
#'                                   lubridate::ymd("1991-01-01"),
#'                                   time_division = "year")
#' year_coord$year <- year_coord$date_label
#' year_coord <- gridcoord::gc_gridcoord(year_coord, "year")
#'
#'
#'
#' # Fit a model to all the data, and then extract predictions:
#' fit <- glm(count ~ year,
#'            family = poisson(link = "log"),
#'            offset = log(population),
#'            data = NM_popcas)
#'
#' # Then use extract_yhat to get out predictions for our observed variable:
#' extract_yhat(nm_county_coord, year_coord, fit, NM_popcas)
#'
#' # Use sample_yhat to draw random samples from the output:
#' sample_yhat(nm_county_coord, year_coord, fit, NM_popcas, n_samples = 10)
#'
#' \dontrun{
#' # We can use INLA models if available as well:
#' fit_inla <- INLA::inla(count ~ year + f(county, model = "iid"),
#'                        family = "poisson",
#'                        control.family = list(link = "log"),
#'                        offset = log(population),
#'                        # These 2 options required to use extract_yhat and sample_yhat
#'                        control.predictor = list(compute = TRUE),
#'                        control.compute = list(config = TRUE),
#'                        data = NM_popcas)
#'
#' extract_yhat(nm_county_coord, year_coord, fit_inla, NM_popcas)
#'
#' sample_yhat(nm_county_coord, year_coord, fit_inla, NM_popcas, n_samples = 10)
#' }
extract_yhat <- function(fit, newdata, ...) {
 UseMethod("extract_yhat", fit)
}

#' @export
extract_yhat.default <- function(fit, newdata, ...) {
  generics::augment(fit, newdata = newdata, ...)
}

# lm, glm, and merMod should be handled by broom and broom.mixed
# So the key ones to handle are INLA and forecast_ARIMA, if I can.

#' @export
extract_yhat.inla <- function(fit, newdata, se_fit = FALSE, ...) {
  if (!requireNamespace("INLA", quietly = TRUE)) {
    stop("The 'INLA' package is required to use inla models in statsurv; ",
         "please install it before continuing")
  }
  # Depending on how INLA is set up, we can get lots of different values back
  # I'm always going to be using the linear predictor.
  if (is.null(fit$marginals.linear.predictor)) {
    stop("Unable to extract fitted values from this inla-object. ",
         "The inla-object must be computed with option ",
         "'control.predictor=list(compute = TRUE) to extract fitted values.")
  }

  inla_link <- get_inla_link(fit)
  inv_link <- function(x) {
    inla_link(x, inverse = TRUE)
  }
  linear_predictor_marginals <- fit$marginals.linear.predictor

  if (se_fit) {
    transformed_marginals <- purrr::map(linear_predictor_marginals, INLA::inla.tmarginal, fun = inv_link)
    fitted_values <- purrr::map_dfr(transformed_marginals, INLA::inla.zmarginal, silent = TRUE)
    fitted_mean <- fitted_values$mean
    fitted_sd <- fitted_values$sd
    if (!is.null(fit$.args$E)) {
      # Fitted values does not include the exposure, so we need to account for that
      fitted_mean <- fitted_mean * fit$.args$E
      fitted_sd <- fitted_sd * fit$.args$E
    }
    newdata$.fitted <- fitted_mean
    newdata$.se.fit <- fitted_sd
  } else {
    fitted_mean <- purrr::map_dbl(linear_predictor_marginals, INLA::inla.emarginal, fun = inv_link)
    if (!is.null(fit$.args$E)) {
      # Fitted values does not include the exposure, so we need to account for that
      fitted_mean <- fitted_mean * fit$.args$E
    }
    newdata$.fitted <- fitted_mean
  }

  response_var <- all.vars(fit$.args$formula)[[1]]
  if (response_var %in% names(newdata)) {
    newdata$.resid <- newdata[[response_var]] - newdata$.fitted
  }
  return(newdata)
}


get_inla_link  <- function(fit) {
  family <- fit$.args$family
  link_name <- fit$.args$control.family[[1]]$link
  # Now we do some terrible things with INLA and evaluating character strings
  if (link_name == "default") {
    link_name <- INLA::inla.models()$likelihood[[family]]$link[[2]]
  }
  function_name <- paste0("INLA::",
                          "inla.link.",
                          link_name)
  inla_link <- eval(parse(text = function_name))
  return(inla_link)
}
