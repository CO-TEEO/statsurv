}
check_mermod <- function(space_coord, time_coord, fit, data, tol = 0.01) {
yhat <- extract_yhat(space_coord, time_coord, fit, data)
test_that("extract_yhat gives a data frame", {expect_true(is.data.frame(yhat))})
row_has_na <- apply(data, 1, function(x) {any(is.na(x))})
non_na_inds <- which(row_has_na == FALSE)
test_that("extract_yhat matches predict", {
expect_equal(yhat[[3]][non_na_inds], unname(predict(fit, type = "response")))
})
}
# Then create some basic data to test on:
time_coord <- generate_date_range(lubridate::ymd("2010-01-01"),
lubridate::ymd("2019-12-21"),
time_division = "year")
space_coord <- data.frame(space_reg = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J"),
stringsAsFactors = FALSE) %>%
gridcoord::gc_gridcoord()
comb_coords <- gridcoord::gc_expand(space_coord, time_coord)
n <- nrow(comb_coords)
na_inds <- 1:10
good_inds <- seq_len(n)[-na_inds]
ey_time <- time_coord
ey_space <- space_coord
x_continuous <- runif(n, min = -5, max = 10) #continuous predictor
x_discrete <- sample(c("L1", "L2", "L3", "L4", "L5"), n, replace = TRUE) #discrete predictor
x_exp <- exp(runif(n, min = 0, max = 5.7))
x_binary <- rbinom(n, 1, 0.5)
# x_pos = runif(n, min = 5)
exposure <- runif(n, min = 5, max = 200)
offset <- log(exposure)
factor_coeffs <- c(-2, 3, 1, 2, -1) %>%
magrittr::set_names(sort(unique(x_discrete)))
space_coeffs <- space_coord %>%
dplyr::rowwise() %>%
dplyr::mutate(space_coeffs = rnorm(sd = 6,n = 1)) %>%
.$space_coeffs %>%
magrittr::set_names(gridcoord::gc_get_labels(space_coord))
ey_data <- cbind(comb_coords, x_continuous, x_discrete, x_exp, x_binary, exposure, offset) %>%
dplyr::mutate(y_lm = 3 + 2.5 * x_continuous + rnorm(n, sd = 2),
y_lm_f = 3 + 2.5 * x_continuous + factor_coeffs[x_discrete] + rnorm(n, sd= 2),
y_logit = rbinom(n, 1, arm::invlogit(x_exp * 0.05 + 1)),
y_logit_f = rbinom(n, 1, arm::invlogit(x_exp * 0.02 - factor_coeffs[x_discrete] / 2)), #Testing changing 0.05 to 0.02
y_pois = rpois(n, exp(2.8 + 0.012 * x_continuous) - 0.20 * x_binary),
y_pois_off = rpois(n, exp(-3 + 0.012 * x_continuous - 0.20 * x_binary + offset)),
y_qpois_off = rnbinom(n,
mu = exp(-3 + 0.012 * x_continuous - 0.20 * x_binary + offset),
size = 0.5),
y_varint = 3 + 2.5 * x_continuous + space_coeffs[.data$space_reg] + rnorm(n, sd = 3)) %>%
dplyr::mutate_at(dplyr::vars(dplyr::starts_with("y_")),
function(x) {x[na_inds] <- NA; return(x)})
formulas <- list(
f_lm = y_lm ~ x_continuous,
f_lm_noint = y_lm ~ x_continuous - 1,
f_lm_f = y_lm_f ~ x_continuous + x_discrete,
f_logit = y_logit ~ x_exp,
f_logit_trans = y_logit ~ log(x_exp),
f_logit_noint = y_logit ~ x_exp - 1,
f_logit_f = y_logit_f ~ x_exp + x_discrete,
f_logit_noint_f = y_logit_f ~ x_exp + x_discrete - 1,
f_pois = y_pois ~ x_continuous + x_binary,
f_pois_f = y_pois ~ x_continuous + factor(x_binary),
f_pois_off_wo = y_pois_off ~ x_continuous + x_binary,
f_pois_off_wi = y_pois_off ~ x_continuous + x_binary + offset(offset),
f_qpois_off_wo = y_qpois_off ~ x_continuous + x_binary,
f_qpois_off_wi = y_qpois_off ~ x_continuous + x_binary + offset(offset)
)
make_matrix <- function(f, df) {
f[[2]] <- rlang::sym("y_null")
matrix <- model.matrix(f, data = df)
m <- colnames(matrix) != "(Intercept)"
matrix[, m, drop = FALSE]
}
check_arima <- function(space, time, fit, data, xreg, n) {
res <- extract_yhat(space, time, fit, data = data, xreg = xreg, n_ahead = length(n))
expect_equal(as.numeric(fit$fitted[-n]),
res$yhat[-n])
if (missing(xreg)) {
expect_equal(as.numeric(forecast::forecast(fit, h = length(n))$mean),
res$yhat[n])
} else {
expect_equal(as.numeric(forecast::forecast(fit, xreg = xreg[n, , drop = FALSE])$mean),
res$yhat[n])
}
expect_true("data.frame" %in% class(res))
}
ac_space <- data.frame(space = "space1",
stringsAsFactors = FALSE)
ac_time <- generate_date_range(lubridate::ymd("2010-01-01"),
lubridate::ymd("2019-12-21"),
time_division = "month")
devtools::load_all(".")
ac_space <- data.frame(space = "space1",
stringsAsFactors = FALSE)
ac_time <- generate_date_range(lubridate::ymd("2010-01-01"),
lubridate::ymd("2019-12-21"),
time_division = "month")
comb_coords <- gridcoord::gc_expand(ac_space, ac_time)
n <- nrow(comb_coords)
na_inds <- 1:10
good_inds <- seq_len(n)[-na_inds]
x_continuous <- runif(n, min = -5, max = 10) #continuous predictor
nu <- as.numeric(arima.sim(list(ar = c(0.9, -0.2)), n = n))
y_ac1 <- 3 + 2.5 * x_continuous + nu
ac_data <- cbind(comb_coords, x_continuous, y_ac1, y_null = 1)
ac_data
?forecast::Arima
xreg
xreg <- make_matrix(y_ac1 ~ x_continuous, ac_data)
ac_data
na_data <- ac_data
na_data[n, "y_ac1"] <- NA
fit_trunc <- forecast::Arima(ac_data$y_ac1[-n],
order = c(1,0,0),
method = "ML",
include.mean = TRUE, # include intercept
transform.pars = FALSE,
xreg = xreg[-n, , drop = FALSE])
fit_na <- forecast::Arima(na_data$y_ac1,
order = c(1,0,0),
method = "ML",
include.mean = TRUE, # include intercept
transform.pars = FALSE,
xreg = xreg)
fit_trunc
fit_na
fit_na$fitted
fit_trunc$fitted
as.numeric(fit_na$fitted)
fitted(fit_na)
fitted(fit_na, h = 2)
fitted(fit_na, h = 1)
fitted(fit_na, h = 0)
fitted(fit_na, h = 3)
residuals(fit_na)
simulate(fit_na)
fit_na$x
forecast::Arima
?fitted.Arima
fitted.Arima
forecast::fitted.Arima
forecast:::fitted.Arima
fit_na$residuals
stats::arima
?arima
(fit <- arima(USAccDeaths, order = c(0,1,1),
seasonal = list(order = c(0,1,1))))
predict(fit, n.ahead = 6)
USAccDeaths
?simulate.Arima
simulate.Arima(fit_na)
simulate(fit_na)
simulate(fit_trunc)
simulate(fit_trunc, 12)
fit_trunc
fit_trunc
ac_data
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE])
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE)
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = fit_trunc$residuals)
fitted(fit_trunc)
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = -fit_trunc$residuals)
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = fit_trunc$residuals)
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = fit_trunc$residuals)
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = fit_trunc$residuals)
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = fit_trunc$residuals)
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = fit_trunc$residuals)
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = fit_trunc$residuals)
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = fit_trunc$residuals)
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = fit_trunc$residuals)
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = fit_trunc$residuals)
simulate(fit_trunc, future = FALSE, innov = fit_trunc$residuals)
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = fit_trunc$residuals)
fitted(fit_trunc)
as.numeric(fitted(fit_trunc))
x <- as.numeric(fitted(fit_trunc))
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = fit_trunc$residuals)
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = fit_trunc$residuals) %>% as.numeric()
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = fit_trunc$residuals) %>% as.numeric() -> y
plot(x, y)
plot(x, x-y)
plot(x, y-x)
plot(y-x, fit_trunc$residuals)
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = fit_trunc$residuals) +
fit_trunc$residuals
x
simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = fit_trunc$residuals) -
fit_trunc$residuals
y <- simulate(fit_trunc, xreg = xreg[-n, , drop = FALSE], future = FALSE, innov = fit_trunc$residuals) -
fit_trunc$residuals
plot(x, y)
# Ok, that works, but I don't think it can tell me what I need to know
simulate(fit_na, xreg = xreg, future = FALSE, innove = fit_na$residuals)
# Ok, that works, but I don't think it can tell me what I need to know
simulate(fit_na, xreg = xreg, future = FALSE, innov = fit_na$residuals)
arima
source('~/r-analysis/statsurv/dev/my_arima.R')
(fit <- arima(USAccDeaths, order = c(0,1,1),
seasonal = list(order = c(0,1,1))))
(fit <- my_arima(USAccDeaths, order = c(0,1,1),
seasonal = list(order = c(0,1,1))))
source('~/r-analysis/statsurv/dev/my_arima.R')
(fit <- my_arima(USAccDeaths, order = c(0,1,1),
seasonal = list(order = c(0,1,1))))
?.Call
source('~/r-analysis/statsurv/dev/my_arima.R')
(fit <- my_arima(USAccDeaths, order = c(0,1,1),
seasonal = list(order = c(0,1,1))))
source('~/r-analysis/statsurv/dev/my_arima.R')
(fit <- my_arima(USAccDeaths, order = c(0,1,1),
seasonal = list(order = c(0,1,1))))
library(fable)
library(fable)
library(tsibble)
library(dplyr)
tourism_melb <- tourism %>%
filter(Region == "Melbourne")
fit <- tourism_melb %>%
model(
ets = ETS(Trips ~ trend("A")),
arima = ARIMA(Trips)
)
fit
?model
?ARIMA
ARIMA(Trips)
model(tourism_melb, ARIMA(Trips))
model(tourism_melb, arima = ARIMA(Trips))
model(tourism_melb, arima = ARIMA(Trips)) %>%
augment()
q <- tourism_melb %>%
filter(Purpose == "Holiday")
model(q, arima = ARIMA(Trips)) %>%
augment()
q
q[nrow(q), "Trips"] <- NA
model(q, arima = ARIMA(Trips)) %>%
augment()
model(q, arima = ARIMA(Trips)) %>%
augment() %>%
tail()
?fabletools::augment
?fabletools::augment.mdl_df
fabletools::augment.mdl_df
fabletools:::augment.mdl_df
fabletools:::augment.mdl_ts
?arima
make_matrix <- function(f, df) {
f[[2]] <- rlang::sym("y_null")
matrix <- model.matrix(f, data = df)
m <- colnames(matrix) != "(Intercept)"
matrix[, m, drop = FALSE]
}
id_time <- seq(1:100)
d <- rnorm(n = length(id_time))
y <- cumsum(d)
arima_data <- tibble::tibble(id_time = id_time, id_space = 1, y = y)
knot <- 42
arima_data <- arima_data %>%
dplyr::mutate(yp = y + ifelse(id_time > knot, (id_time - knot) * 0.2, 0))
arima_data
make_matrix <- function(f, df) {
f[[2]] <- rlang::sym("y_null")
matrix <- model.matrix(f, data = df)
m <- colnames(matrix) != "(Intercept)"
matrix[, m, drop = FALSE]
}
make_matrix(y ~ id_time + pmax(id_time-36, 0))
make_matrix(y ~ id_time + pmax(id_time-36, 0), df = arima_data)
model.matrix.default(y ~ id_time + pmax(id_time-36, 0), data = arima_data)
model.matrix(y ~ id_time + pmax(id_time-36, 0), data = arima_data)
model.matrix(z ~ id_time + pmax(id_time-36, 0), data = arima_data)
model.matrix(y ~ id_time + pmax(id_time-36, 0), data = arima_data)
gen_xreg <- function(f, data) {
matrix <- model.matrix(f, data = data)
m <- colnames(matrix) != "(Intercept)"
matrix[, m, drop = FALSE]
}
gen_xreg(y ~ id_time + pmax(id_time - 36, 0), arima_data)
xreg <- gen_xreg(y ~ id_time + pmax(id_time - 36, 0), arima_data)
f <- y ~ id_time + pmax(id_time-36, 0)
all.vars(f)
f[[1]]
f[[2]]
lm
?model.response
?model.frame
mode.frame(f)
model.frame(f)
model.frame(f) %>% model.response()
f
gen_resp <- function(f, data) {
model.response(model.frame(f, data = data))
}
?arima
arima2 <- function(f, data, ...) {
xreg <- gen_xreg(f, data)
resp <- gen_resp(f, data)
arima(resp, xreg = xreg, ...)
}
arima2(y ~ id_time + pmax(id_time-36, 0), arima_data, order = c(1,1,0), include.mean = TRUE)
arima(y, order = c(1, 1, 0), include.mean = TRUE)
arima2(y ~ 1, arima_data, order = c(1,1,0), include.mean = TRUE)
arima2(y ~ 1, arima_data, order = c(1,1,0), include.mean = TRUE) -> fit
class(fit)
str(fit)
fit$call
lm(y ~ id_time, data = arima_data)
lm(y ~ id_time, data = arima_data) -> fit_lm
fit_lm$call
fit_lm$model
fit_lm$call
class(fit_lm$call)
str(fit_lm)
fit_lm$terms
arima2 <- function(f, data, ...) {
xreg <- gen_xreg(f, data)
resp <- gen_resp(f, data)
fit <- arima(resp, xreg = xreg, ...)
fit$formula <- f
fit$data <- data
class(fit) <- c("arima2", class(fit))
}
arima2(y ~ 1, arima_data, order = c(1,1,0), include.mean = TRUE)
fit <- arima2(y ~ 1, arima_data, order = c(1,1,0), include.mean = TRUE)
fit
arima2 <- function(f, data, ...) {
xreg <- gen_xreg(f, data)
resp <- gen_resp(f, data)
fit <- arima(resp, xreg = xreg, ...)
fit$formula <- f
fit$data <- data
class(fit) <- c("arima2", class(fit))
fit
}
fit <- arima2(y ~ 1, arima_data, order = c(1,1,0), include.mean = TRUE)
fit
devtools::load_all(".")
arima_data
input_data <- prepare_prediction_data(arima_data, outcome_cols = y, split_id = 100, prep_strategy = "truncate")
fit <- arima2(y ~ 1, input_data, order = c(1,1,0), include.mean = TRUE)
fit
arima2 <- function(f, data, ...) {
xreg <- gen_xreg(f, data)
resp <- gen_resp(f, data)
fit <- arima(resp, xreg = xreg, ...)
fit$formula <- f
fit$data <- data
fit$fitted <- rep - fit$residuals
class(fit) <- c("arima2", class(fit))
fit
}
fit <- arima2(y ~ 1, input_data, order = c(1,1,0), include.mean = TRUE)
arima2 <- function(f, data, ...) {
xreg <- gen_xreg(f, data)
resp <- gen_resp(f, data)
fit <- arima(resp, xreg = xreg, ...)
fit$formula <- f
fit$data <- data
fit$fitted <- resp - fit$residuals
class(fit) <- c("arima2", class(fit))
fit
}
input_data <- prepare_prediction_data(arima_data, outcome_cols = y, split_id = 100, prep_strategy = "truncate")
fit <- arima2(y ~ 1, input_data, order = c(1,1,0), include.mean = TRUE)
fit$fitted
?predict.arima0
preidct(arima2)
predict(arima2)
predict.arima
class(fit)
new_xreg <- gen_xreg(fit$formula, newdata)
# What's the cleanest way to get only the new rows?
# Is it an anti-join?
# Or is it
vars <- all.vars(fit$formula)
vars
fit <- arima2(y ~ id_time + pmax(id_time - 36, 0), input_data, order = c(1,1,0), include.mean = TRUE)
fit
newdata <- arima_data
n_ahead <- nrow(newdata) - length(fit$fitted)
n_ahead
# What's the cleanest way to get only the new rows?
# Is it an anti-join?
# Or is it
vars <- all.vars(fit$formula)
vars
# What's the cleanest way to get only the new rows?
# Is it an anti-join?
# Or is it
vars <- all.vars(fit$formula)
old_data <- fit$data %>%
dplyr::select(vars)
old_data <- fit$data %>%
dplyr::select(dplyr::all_of(vars))
new_data <- newdata %>%
dplyr::select(dplyr::all_of(vars))
newnew_data <- dplyr::anti_join(new_data, old_data, by = vars)
newnew_data
xreg <- gen_xreg(fit$formula, newnew_data)
xreg
stats::predict(fit, n.ahead = n_ahead, new_xreg = xreg)
fit$model
extract_yhat.arima2 <- function(fit, newdata) {
n_ahead <- nrow(newdata) - length(fit$fitted)
new_xreg <- gen_xreg(fit$formula, newdata)
# What's the cleanest way to get only the new rows?
# Is it an anti-join?
# Or is it
vars <- all.vars(fit$formula)
old_data <- fit$data %>%
dplyr::select(dplyr::all_of(vars))
new_data <- newdata %>%
dplyr::select(dplyr::all_of(vars))
newnew_data <- dplyr::anti_join(new_data, old_data, by = vars)
xreg <- gen_xreg(fit$formula, newnew_data)
return(stats::predict(fit, n.ahead = n_ahead, newxreg = xreg))
if (missing(xreg)) {
new_predictions <- as.numeric(
forecast::forecast(fit, h = n_ahead)$mean
)
} else {
rows_to_use <- seq(nrow(xreg) - n_ahead + 1, nrow(xreg))
new_xreg <- xreg[rows_to_use, , drop = FALSE]
new_predictions <- as.numeric(
forecast::forecast(fit, h = n_ahead, xreg = new_xreg)$mean
)
}
old_predictions <- as.numeric(fit$fitted)
predictions <- c(old_predictions, new_predictions)
data$.fitted <- predictions
return(data)
}
stats::predict(fit, n.ahead = n_ahead, newxreg = xreg)
extract_yhat.arima2 <- function(fit, newdata) {
n_ahead <- nrow(newdata) - length(fit$fitted)
new_xreg <- gen_xreg(fit$formula, newdata)
# What's the cleanest way to get only the new rows?
# Is it an anti-join?
# Or is it
vars <- all.vars(fit$formula)
old_data <- fit$data %>%
dplyr::select(dplyr::all_of(vars))
new_data <- newdata %>%
dplyr::select(dplyr::all_of(vars))
newnew_data <- dplyr::anti_join(new_data, old_data, by = vars)
xreg <- gen_xreg(fit$formula, newnew_data)
new_predictions <- as.numeric(stats::predict(fit, n.ahead = n_ahead, newxreg = xreg)$pred)
old_predictions <- as.numeric(fit$fitted)
predictions <- c(old_predictions, new_predictions) #I don't know if we can assume this
newdata$.fitted <- predictions
return(newdata)
if (missing(xreg)) {
new_predictions <- as.numeric(
forecast::forecast(fit, h = n_ahead)$mean
)
} else {
rows_to_use <- seq(nrow(xreg) - n_ahead + 1, nrow(xreg))
new_xreg <- xreg[rows_to_use, , drop = FALSE]
new_predictions <- as.numeric(
forecast::forecast(fit, h = n_ahead, xreg = new_xreg)$mean
)
}
old_predictions <- as.numeric(fit$fitted)
predictions <- c(old_predictions, new_predictions)
data$.fitted <- predictions
return(data)
}
extract_yhat(fit, arima_data)
?fabletools::augment()
fabletools:::augment.mdl_ts
?fable::ARIMA
?fable::model
?model
model
fabletools:::model.tbl_ts
?fabletools::estimate()
estimate(tourism_melb, ARIMA(Trips))
estimate(tourism_melb, ARIMA(Trips))$model
estimate(tourism_melb, ARIMA(Trips))
estimate(tourism_melb, ARIMA(Trips)) -> q
clss(q)
class(q)
q$fit
q$fit$model
fit <- tourism_melb %>%
model(
ets = ETS(Trips ~ trend("A")),
arima = ARIMA(Trips)
)
fit
fit$arima
fit$arima[[4]]
class(fit$arima)
?augment.lm
simulate.Arima
?simulate
?forecast:::simulate.Arima()
?predict.Arima
xreg
input_data <- prepare_prediction_data(arima_data, outcome_cols = y, split_id = 100, prep_strategy = "truncate")
input_data
input_xreg <- gen_xreg(y ~ id_time + pmax(id_time - 36, 0), input_data)
fit_base <- arima(input_data$y, order = c(1, 1, 0), xreg = input_xreg, include_mean = TRUE)
fit_base <- arima(input_data$y, order = c(1, 1, 0), xreg = input_xreg, include.mean = TRUE)
fit_base
arima_xreg <- gen_xreg(y ~ id_time + pmax(id_time - 36, 0), arima_data)
arima_xreg
fit <- fit_base
newdata <- arima_data
newxreg <- arima_xreg
str(fit)
fit$call
